# -*- coding: utf-8 -*-
"""SpokenLanguageTransform.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bNN7p-PmSMggdnKYdL1VIZjZ1BpHOh3C
"""

!pip install -q soundfile
import soundfile as sf
from scipy import signal
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import librosa
from librosa import display

from google.colab import drive
drive.mount('/content/gdrive')

import os
import numpy
import pandas as pd
from torch.optim import Adam

import time
import torch.nn.functional as F


directory='gdrive/My Drive/spoken/'

lene=0
label = []
for filename in os.listdir(directory):
    lene=lene+1
    label.append(filename[:2])

file = []
for filename in os.listdir(directory):
    file.append(filename)

"""**Reading Audio Files**"""

mel=[]
min=0.0
max=255.0
for i in range(lene):
  data, samplerate = sf.read(directory+file[i])
  mels =librosa.feature.melspectrogram(data, sr=samplerate)
  mels = numpy.log(mels + 1e-9)
  
  X_std = (mels - mels.min()) / (mels.max() - mels.min())*255
  


  img = X_std.astype(numpy.uint8)
  img = numpy.flip(img, axis=0) # put low frequencies at the bottom in image
  img = 255-img
  mel.append(img) 
  if(i%1000==0):
    print(i)

from google.colab import files
import pickle
with open("spectrum.txt", "wb") as fp:   #Pickling
  pickle.dump(mel, fp)
 
files.download('spectrum.txt')

import pickle
with open("gdrive/My Drive/spectrum (1).txt", "rb") as fp:   # Unpickling
  b = pickle.load(fp)

data = {'filename':file,
        'language':label,
        'spectrum':b}
df = pd.DataFrame(data)
print(df.head())

df=df.drop([1978,2026,3616])
df = df.reset_index(drop=True)

import sklearn
for i in range(50):
   df = sklearn.utils.shuffle(df)
df = df.reset_index(drop=True)
print(df.head())

df = pd.concat([df,pd.get_dummies(df['language'], prefix='lang')],axis=1)

def onehotcode(i):
  y=torch.tensor([df['lang_de'][i],df['lang_en'][i],df['lang_es'][i]])
  y=y.float()
  return y

"""**Batch Formation**"""

data=[]
output=[]
for i in range(0,10000,5):
  for j in range(i,i+5,1):
    if j%5 == 0:
      t=torch.tensor(df['spectrum'][j].reshape(1,1,128,313))
      y=onehotcode(j).reshape(1,3)
   
    else:
        t = torch.cat((torch.tensor(df['spectrum'][j].reshape(1,1,128,313)), t), 0)
        y=torch.cat((onehotcode(j).reshape(1,3),y),0)
  t=torch.tensor(t,dtype=torch.float32)
  data.append(t)
  output.append(y)
len(data)

"""**Neural Network Architecture**"""

class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels,size):
        super().__init__()
        
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, size, 1, 1),
            nn.Dropout(0.2),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.MaxPool2d(3, stride=(2,2))
        )
        
        
        

        self._init_weights()
        
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.zeros_(m.bias)
        
    def forward(self, x):
        x = self.conv1(x)
        
        
        
        return x
      


class ConvBlock1(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1),
            nn.Dropout(0.2),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.MaxPool2d(3, stride=(2,2))
        )
        
        
        

        self._init_weights()
        
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                a=np.array([[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]],[[[ 0.57735027,0.81649658,0.],
 [ 0.57735027,-0.40824829,0.70710678],
 [ 0.57735027,-0.40824829,-0.70710678]]]])
                w = torch.from_numpy(a).type(torch.FloatTensor)
                m.weight = torch.nn.Parameter(w)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.zeros_(m.bias)
        
    def forward(self, x):
        x = self.conv1(x)
        
        
        return x
      
class Classifier(nn.Module):
    def __init__(self):
        super().__init__()
        
        self.conva = nn.Sequential(
            ConvBlock1(in_channels=1, out_channels=16),
        ) 
        self.convb = nn.Sequential(
            ConvBlock(in_channels=16, out_channels=32,size=5),
        )
        self.convc = nn.Sequential(
            ConvBlock(in_channels=32, out_channels=32,size=3),
            
        )
       
        self.rnn = nn.GRU(3456, 128, 1,batch_first=True)
        self.fc =  nn.Linear(128, 3)
           
        
        self.sig = nn.Sigmoid()
        self.dropout = nn.Dropout(0.2)
        

    def forward(self, x):
        hidden = self.init_hidden()
        
        x = self.conva(x)
        
        x = self.convb(x)
        
        x = self.convc(x)
        
        x = self.convc(x)
       
        
        
        x, hidden = self.rnn(x.view(5,1,3456),hidden)
        
        x=x.reshape(5,128)
        
        x=self.dropout(x)
        x = self.fc(x)
        
        x=self.sig(x)
        return x
    
    def init_hidden(self):
        
        hidden = torch.zeros(1,5,128)
        hidden=hidden.cuda()
        return hidden

"""**Training Details**"""

num_epochs = 10
   
    
lr = 1e-4
eta_min = 1e-5
t_max = 10

    
    
    
model = Classifier().cuda()
criterion = nn.BCELoss().cuda()
optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)

"""**Training Function**"""

a=[]
b=[]
for epoch in range(15):
    start_time = time.time()
    model.train()
    avg_loss = 0.
    z=0
    for i in range(1900):
            model.zero_grad()
            
            
            
            preds = model(data[i].cuda())
            
    
            loss = criterion(preds, output[i].cuda())
            
            loss.backward()
            optimizer.step()

            avg_loss += loss.item() / 1900
            
            aprox = torch.round(preds.squeeze())
            aprox=aprox.cuda()
            for k in range(5):
              
                if torch.all(torch.eq(aprox[k], output[i].cuda()[k])):
                  z=z+1
            
    model.eval()
      
    
      
        
        
    

    if (epoch + 1) % 1 == 0:
        elapsed = time.time() - start_time
        print('Epoch :',epoch+1, ' avg_train_loss:' ,avg_loss ,  'time:' ,elapsed,'Training Accuracy:',z*100/(9500)  )
        a.append(avg_loss)
        
    l=0
    final=0
    m=0
    if (epoch+1) % 1 == 0:
      for j in range(1900,1950,1):
            l=l+1
            
            preds = model(data[j].cuda())
            
            y=output[j]
            y=y.cuda()
            loss = criterion(preds, y)
            final+=loss.item()/50
            aprox = torch.round(preds.squeeze())
            aprox=aprox.cuda()
            for k in range(5):
              
              if torch.all(torch.eq(aprox[k],y[k])):
                m=m+1
      
      
      print("Validation Loss :",final)
      print("Validation Accuracy :",(m*100)/(250),"%")
      b.append(final)

"""**Training Loss And Validation Loss**"""

import matplotlib.pyplot as plt
fig = plt.figure()
plt.plot(a)
plt.plot(b)
fig.suptitle('Losses')
plt.xlabel('No. of epochs')
plt.ylabel('Loss')        
plt.legend(['Training Loss', 'Validation Loss'])

torch.cuda.memory_allocated()

"""**Testing **"""

model(data[1899].cuda())

net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])
>>> output = net(input_var)



preds = model(data[1999].cuda())
            
aprox = torch.round(preds.squeeze())
print(aprox)
for l in range(5):
  print("For file",i*5)
  if aprox[l]==torch.tensor([0,0,1]).cuda():
    print('French')
  elif aprox[l]==torch.tensor([0,1,0].cuda()):
    print('English')
  else:
    print('German')

df.head()

data, samplerate = sf.read(directory+file[1])
mels =librosa.feature.melspectrogram(data, sr=samplerate)
mels = numpy.log(mels + 1e-9)
  
X_std = (mels - mels.min()) / (mels.max() - mels.min())*255
  


img = X_std.astype(numpy.uint8)
img = numpy.flip(img, axis=0) # put low frequencies at the bottom in image
img = 255-img
mel.append(img)

librosa.display.specshow(img)

cgb

